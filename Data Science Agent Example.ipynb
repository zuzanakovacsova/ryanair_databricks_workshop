{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b560799-0d41-4570-adfe-e7b9b59bd081",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Profile wine_reviews_data schema and nulls"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, when\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.table('dilshad_shawki.test.wine_reviews_data')\n",
    "display(df.limit(5))\n",
    "\n",
    "# Show schema\n",
    "print('Schema:')\n",
    "df.printSchema()\n",
    "\n",
    "# Null counts for key columns\n",
    "key_cols = ['country', 'description', 'points', 'price', 'province', 'region_1', 'region_2', 'variety', 'winery']\n",
    "def null_count_expr(c):\n",
    "    return count(when((col(c).isNull()) | (col(c) == ''), c)).alias(c)\n",
    "null_counts = df.select([null_count_expr(c) for c in key_cols])\n",
    "display(null_counts)\n",
    "\n",
    "# UDF to safely convert to float\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "safe_float_udf = udf(safe_float, FloatType())\n",
    "\n",
    "safe_df = df.withColumn('points_float', safe_float_udf(col('points')))\n",
    "safe_df = safe_df.withColumn('price_float', safe_float_udf(col('price')))\n",
    "\n",
    "stats = safe_df.select(\n",
    "    F.min('points_float').alias('min_points'),\n",
    "    F.max('points_float').alias('max_points'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.min('price_float').alias('min_price'),\n",
    "    F.max('price_float').alias('max_price'),\n",
    "    F.avg('price_float').alias('avg_price')\n",
    ")\n",
    "display(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "482679a9-dfe4-4d0c-a347-b9b2b1e392ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Trend analysis by country and variety"
    }
   },
   "outputs": [],
   "source": [
    "%restart_python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2d3dfa-6c41-4e9c-93bc-a5c6661d9d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregate review counts, average points, and average price by country and variety\n",
    "trend_df = df.withColumn('points_float', safe_float_udf(col('points')))\n",
    "trend_df = trend_df.withColumn('price_float', safe_float_udf(col('price')))\n",
    "\n",
    "country_trends = trend_df.groupBy('country').agg(\n",
    "    F.count('*').alias('review_count'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.avg('price_float').alias('avg_price')\n",
    ").orderBy(F.desc('review_count'))\n",
    "display(country_trends)\n",
    "\n",
    "variety_trends = trend_df.groupBy('variety').agg(\n",
    "    F.count('*').alias('review_count'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.avg('price_float').alias('avg_price')\n",
    ").orderBy(F.desc('review_count'))\n",
    "display(variety_trends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fddd0b39-368b-427a-8653-000058452e1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test display rendering with small DataFrame"
    }
   },
   "outputs": [],
   "source": [
    "# Test if display works with a simple DataFrame\n",
    "from pyspark.sql import Row\n",
    "simple_df = spark.createDataFrame([Row(a=1, b=2), Row(a=3, b=4)])\n",
    "display(simple_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f8ff639-bea8-4059-9f81-09f98f5480fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Sentiment analysis of wine descriptions"
    }
   },
   "outputs": [],
   "source": [
    "%pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e611e34-db4c-4a52-98e6-92268e808b02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72d3c797-4548-4c25-9098-59dee0d0db10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sentiment analysis using TextBlob\n",
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "def get_sentiment(text):\n",
    "    if text:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    return None\n",
    "sentiment_udf = udf(get_sentiment, FloatType())\n",
    "\n",
    "sentiment_df = df.withColumn('sentiment', sentiment_udf(col('description')))\n",
    "\n",
    "# Aggregate average sentiment by country and variety\n",
    "country_sentiment = sentiment_df.groupBy('country').agg(F.avg('sentiment').alias('avg_sentiment')).orderBy(F.desc('avg_sentiment')).limit(10)\n",
    "display(country_sentiment)\n",
    "\n",
    "variety_sentiment = sentiment_df.groupBy('variety').agg(F.avg('sentiment').alias('avg_sentiment')).orderBy(F.desc('avg_sentiment')).limit(10)\n",
    "display(variety_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab6b052f-a596-4cfb-8dba-5bb833e5a787",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Slice and dice by country, variety, region, and price bands"
    }
   },
   "outputs": [],
   "source": [
    "# Add price bands for analysis\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "price_bins = [0, 15, 30, 50, 100, 1000, 10000]\n",
    "price_labels = ['<15', '15-30', '30-50', '50-100', '100-1000', '1000+']\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "sentiment_df = df.withColumn('points_float', safe_float_udf(col('points')))\n",
    "sentiment_df = sentiment_df.withColumn('price_float', safe_float_udf(col('price')))\n",
    "sentiment_df = sentiment_df.withColumn('sentiment', sentiment_udf(col('description')))\n",
    "\n",
    "# Create price band column\n",
    "sentiment_df = sentiment_df.withColumn(\n",
    "    'price_band',\n",
    "    when(col('price_float') < 15, '<15')\n",
    "    .when((col('price_float') >= 15) & (col('price_float') < 30), '15-30')\n",
    "    .when((col('price_float') >= 30) & (col('price_float') < 50), '30-50')\n",
    "    .when((col('price_float') >= 50) & (col('price_float') < 100), '50-100')\n",
    "    .when((col('price_float') >= 100) & (col('price_float') < 1000), '100-1000')\n",
    "    .when(col('price_float') >= 1000, '1000+')\n",
    "    .otherwise('Unknown')\n",
    ")\n",
    "\n",
    "# Aggregate by country and price band\n",
    "country_price = sentiment_df.groupBy('country', 'price_band').agg(\n",
    "    F.count('*').alias('review_count'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.avg('sentiment').alias('avg_sentiment')\n",
    ").orderBy(F.desc('review_count'))\n",
    "display(country_price)\n",
    "\n",
    "# Aggregate by variety and price band\n",
    "variety_price = sentiment_df.groupBy('variety', 'price_band').agg(\n",
    "    F.count('*').alias('review_count'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.avg('sentiment').alias('avg_sentiment')\n",
    ").orderBy(F.desc('review_count'))\n",
    "display(variety_price)\n",
    "\n",
    "# Aggregate by region_1 and price band\n",
    "region_price = sentiment_df.groupBy('region_1', 'price_band').agg(\n",
    "    F.count('*').alias('review_count'),\n",
    "    F.avg('points_float').alias('avg_points'),\n",
    "    F.avg('sentiment').alias('avg_sentiment')\n",
    ").orderBy(F.desc('review_count'))\n",
    "display(region_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce85087-1d4c-44c0-8f1e-6c4946a8fe0b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Identify best and worst wines"
    }
   },
   "outputs": [],
   "source": [
    "# Identify best and worst wines by points, sentiment, and price-to-quality ratio\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Add numeric columns if not already present\n",
    "scored_df = df.withColumn('points_float', safe_float_udf(col('points')))\n",
    "scored_df = scored_df.withColumn('price_float', safe_float_udf(col('price')))\n",
    "scored_df = scored_df.withColumn('sentiment', sentiment_udf(col('description')))\n",
    "\n",
    "# Price-to-quality ratio (points per dollar)\n",
    "scored_df = scored_df.withColumn('ptq_ratio', F.col('points_float') / F.col('price_float'))\n",
    "\n",
    "# Best wines: top by points, sentiment, and ptq_ratio\n",
    "best_points = scored_df.orderBy(F.desc('points_float')).select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(best_points)\n",
    "\n",
    "best_sentiment = scored_df.orderBy(F.desc('sentiment')).select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(best_sentiment)\n",
    "\n",
    "best_ptq = scored_df.orderBy(F.desc('ptq_ratio')).select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(best_ptq)\n",
    "\n",
    "# Worst wines: bottom by points, sentiment, and ptq_ratio (filter for reasonable price and points)\n",
    "worst_points = scored_df.filter(F.col('points_float') > 0).orderBy('points_float').select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(worst_points)\n",
    "\n",
    "worst_sentiment = scored_df.orderBy('sentiment').select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(worst_sentiment)\n",
    "\n",
    "worst_ptq = scored_df.filter(F.col('price_float') > 0).orderBy('ptq_ratio').select('title', 'country', 'variety', 'points_float', 'price_float', 'sentiment', 'ptq_ratio').limit(10)\n",
    "display(worst_ptq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ded7c46c-c4da-4dc9-9564-b7269b053854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Wine Reviews Data Analysis: Final Review and Conclusion**\n",
    "\n",
    "*Summary of Findings:*\n",
    "* The dataset covers a wide range of wines, with the US, Italy, and France leading in review volume. France and Austria have the highest average points, while Pinot Noir and Bordeaux-style blends are top-rated varieties.\n",
    "* Sentiment analysis shows Japan, Luxembourg, and South Korea have the most positively described wines, and rare varieties like Karasakiz and Moscato di Noto receive the most favorable language.\n",
    "* Slicing by price bands reveals that higher-priced wines (50-100 and above) tend to score better in both points and sentiment, especially from regions like Napa Valley and Bordeaux.\n",
    "* The best wines by points are Italian Merlot and Prugnolo Gentile, and French Chardonnay. By sentiment, US Chardonnay and Pinot Noir stand out. For value, US Merlot and Pinot Gris, and Portuguese Red offer the best price-to-quality ratios.\n",
    "* The worst wines by points and sentiment are often low-cost or generic blends, with some expensive wines underperforming on a price-to-quality basis.\n",
    "\n",
    "*Conclusion:*\n",
    "The analysis highlights that while classic regions and varieties dominate in quality and reputation, there are hidden gems offering exceptional value and positive sentiment. Consumers seeking the best experience should consider both expert scores and review sentiment, and explore mid-to-high price bands for the best balance of quality and value. Conversely, caution is advised with generic blends and some high-priced wines that may not deliver on expectations.\n",
    "\n",
    "*Actionable Insights:*\n",
    "* For premium quality, focus on French, Italian, and US wines in the 50-100 price band, especially Pinot Noir, Bordeaux blends, and Chardonnay.\n",
    "* For value, seek out US Merlot, Pinot Gris, and Portuguese Red in the lower price bands.\n",
    "* Use sentiment trends to discover emerging regions and varieties with strong consumer appeal.\n",
    "\n",
    "This comprehensive analysis provides a data-driven guide for wine selection, balancing expert ratings, consumer sentiment, and value."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Data Science Agent Example",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}